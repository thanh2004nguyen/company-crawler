"""
Handelsregister.de Scraper
S·ª≠ d·ª•ng Playwright ƒë·ªÉ scrape d·ªØ li·ªáu t·ª´ handelsregister.de
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
import time
import logging
import hashlib
import io
from typing import Dict
from playwright.sync_api import sync_playwright, Page
from utils import HandelsregisterXMLParser, PDFDataExtractor
# from models.company_model import CompanyData  # Removed - not needed

# Force UTF-8 encoding cho console
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    except AttributeError:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class HandelsregisterScraper:
    """Scraper cho handelsregister.de s·ª≠ d·ª•ng Playwright"""
    
    def __init__(self, headless: bool = False, language: str = 'FR'):
        self.search_url = "https://www.handelsregister.de/rp_web/normalesuche/welcome.xhtml"
        self.headless = headless
        self.language = language  # FR (French), DE (German), EN (English)
        self.xml_parser = HandelsregisterXMLParser()
        self.pdf_extractor = PDFDataExtractor()
        
    def scrape_company(self, company_name: str, registernummer: str, ust_idnr: str) -> Dict:
        """
        Scrape d·ªØ li·ªáu c√¥ng ty t·ª´ handelsregister.de
        
        Args:
            company_name: T√™n c√¥ng ty
            registernummer: S·ªë ƒëƒÉng k√Ω (vd: "HRB182742")
            ust_idnr: M√£ s·ªë thu·∫ø VAT
            
        Returns:
            Dict ch·ª©a d·ªØ li·ªáu ƒë√£ scrape
        """
        logger.info(f"üöÄ B·∫Øt ƒë·∫ßu scrape: {company_name}")
        
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=self.headless)
            page = browser.new_page()
            
            try:
                # 1. Truy c·∫≠p trang
                logger.info(f"üîó Truy c·∫≠p: {self.search_url}")
                page.goto(self.search_url, wait_until='networkidle')
                page.wait_for_timeout(2000)
                
                # 2. Ch·ªçn ng√¥n ng·ªØ (lu√¥n ch·ªçn)
                self._select_language(page)
                
                # 3. ƒêi·ªÅn form
                self._fill_search_form(page, company_name, registernummer)
                
                # 4. Click search
                self._click_search_button(page)
                
                # 5. T·∫°o th∆∞ m·ª•c l∆∞u files
                download_dir = self._create_download_directory(company_name)
                logger.info(f"üìÅ Download directory: {download_dir}")
                
                # 6. LU√îN LU√îN CRAWL - ƒê·ª£i v√† check k·∫øt qu·∫£ t√¨m ki·∫øm
                logger.info("‚è±Ô∏è  ƒêang ƒë·ª£i k·∫øt qu·∫£ t√¨m ki·∫øm...")
                page.wait_for_load_state('networkidle')
                page.wait_for_timeout(5000)
                
                # 7. Ki·ªÉm tra c√≥ k·∫øt qu·∫£
                if self._check_results_found(page):
                    logger.info("‚úÖ ƒê√£ t√¨m th·∫•y company - B·∫Øt ƒë·∫ßu download files (ƒë√® l√™n files c≈©)")
                    
                    # 8. Download AD (PDF) v√† SI (XML) - ƒê√® l√™n files c≈© n·∫øu c√≥
                    self._download_documents(page, download_dir, registernummer)
                    
                    # 9. Extract data t·ª´ PDF (tr∆∞·ªõc)
                    pdf_data = self._extract_pdf_data(download_dir, registernummer)
                    
                    # 10. Extract data t·ª´ XML (sau - override PDF)
                    xml_data = self._extract_xml_data(download_dir, registernummer)
                    
                    # 11. Combine data (XML override PDF v√¨ c√≥ format t·ªët h∆°n)
                    data = {
                        'registernummer': registernummer,
                        'download_directory': download_dir,
                        **pdf_data,  # PDF data tr∆∞·ªõc (backup)
                        **xml_data   # XML data sau (override - priority cao h∆°n)
                    }
                else:
                    logger.warning("‚ùå Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£")
                    data = {
                        'registernummer': registernummer,
                        'download_directory': download_dir
                    }
                
                browser.close()
                return data
                
            except Exception as e:
                logger.error(f"‚ùå L·ªói: {str(e)}")
                browser.close()
                return {}
    
    def _select_language(self, page: Page):
        """Ch·ªçn ng√¥n ng·ªØ t·ª´ dropdown menu"""
        try:
            logger.info(f"üåç Ch·ªçn ng√¥n ng·ªØ: {self.language}")
            
            # Hover ƒë·ªÉ m·ªü dropdown
            page.hover('li#localSubMenu')
            page.wait_for_timeout(1000)
            
            # ƒê·ª£i menu hi·ªÉn th·ªã v·ªõi timeout d√†i h∆°n
            try:
                page.wait_for_selector('ul.ui-menu-list[style*="display: block"]', state='visible', timeout=10000)
            except:
                logger.warning("‚ö†Ô∏è  Dropdown menu kh√¥ng hi·ªÉn th·ªã, th·ª≠ click tr·ª±c ti·∫øp")
            
            # Click ng√¥n ng·ªØ
            language_id = self.language.lower()
            page.click(f'a#{language_id}', timeout=5000)
            
            # ƒê·ª£i reload
            page.wait_for_load_state('networkidle', timeout=30000)
            page.wait_for_timeout(2000)
            
            logger.info(f"‚úÖ ƒê√£ ch·ªçn ng√¥n ng·ªØ: {self.language}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ ch·ªçn ng√¥n ng·ªØ: {str(e)}")
            logger.info("‚ÑπÔ∏è  Ti·∫øp t·ª•c v·ªõi ng√¥n ng·ªØ m·∫∑c ƒë·ªãnh (German)")
    
    def _fill_search_form(self, page: Page, company_name: str, registernummer: str):
        """ƒêi·ªÅn form t√¨m ki·∫øm"""
        try:
            register_type = self._get_register_type(registernummer)
            register_number = self._get_register_number(registernummer)
            
            logger.info(f"üìù ƒêi·ªÅn form: {company_name} - {register_type}{register_number}")
            
            # ƒêi·ªÅn t√™n c√¥ng ty
            page.fill('textarea#form\\:schlagwoerter', company_name)
            page.wait_for_timeout(500)
            
            # Ch·ªçn lo·∫°i register
            page.click('label#form\\:registerArt_label')
            page.wait_for_timeout(500)
            page.click(f'li[data-label="{register_type}"]')
            page.wait_for_timeout(500)
            
            # ƒêi·ªÅn s·ªë register
            page.fill('input#form\\:registerNummer', register_number)
            page.wait_for_timeout(500)
            
            logger.info("‚úÖ ƒê√£ ƒëi·ªÅn form xong")
        except Exception as e:
            logger.error(f"‚ùå L·ªói ƒëi·ªÅn form: {str(e)}")
    
    def _click_search_button(self, page: Page):
        """Click n√∫t t√¨m ki·∫øm"""
        try:
            logger.info("üîç Click n√∫t t√¨m ki·∫øm")
            
            # Th·ª≠ nhi·ªÅu selector kh√°c nhau
            selectors = [
                'button#form\\:btnSuche',  # Button ID
                'span.ui-button-text:has-text("Suchen")',  # German
                'span.ui-button-text:has-text("Rechercher")',  # French
                'span.ui-button-text:has-text("Search")',  # English
                'button[type="submit"]',  # Generic submit
            ]
            
            clicked = False
            for selector in selectors:
                try:
                    locator = page.locator(selector)
                    count = locator.count()
                    if count > 0:
                        page.click(selector, timeout=3000)
                        logger.info(f"‚úÖ Clicked button with selector: {selector}")
                        clicked = True
                        break
                except:
                    continue
            
            if not clicked:
                logger.error("‚ùå Kh√¥ng t√¨m th·∫•y search button")
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói click search: {str(e)}")
    
    def _check_results_found(self, page: Page) -> bool:
        """Ki·ªÉm tra c√≥ t√¨m th·∫•y k·∫øt qu·∫£ kh√¥ng"""
        try:
            results_table = page.query_selector('tr.ui-widget-content')
            if results_table:
                page_text = page.inner_text('body')
                if 'Amtsgericht' in page_text or 'HRB' in page_text:
                    return True
            return False
        except:
            return False
    
    def _get_register_type(self, registernummer: str) -> str:
        """Extract lo·∫°i register"""
        types = ['HRB', 'HRA', 'GnR', 'PR', 'VR', 'GsR']
        for reg_type in types:
            if registernummer.startswith(reg_type):
                return reg_type
        return 'HRB'
    
    def _get_register_number(self, registernummer: str) -> str:
        """Extract s·ªë register"""
        for reg_type in ['HRB', 'HRA', 'GnR', 'PR', 'VR', 'GsR']:
            if registernummer.startswith(reg_type):
                return registernummer[len(reg_type):]
        return registernummer
    
    def _create_download_directory(self, company_name: str) -> str:
        """T·∫°o th∆∞ m·ª•c l∆∞u files download - L∆∞u v√†o data/companies/"""
        import re
        # T·∫°o ƒë∆∞·ªùng d·∫´n: data/companies/
        base_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data')
        download_dir = os.path.join(base_dir, 'companies')
        
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
        os.makedirs(download_dir, exist_ok=True)
        
        logger.info(f"üìÅ S·ª≠ d·ª•ng th∆∞ m·ª•c: {download_dir}")
        return download_dir
    
    def _check_existing_files(self, download_dir: str, registernummer: str) -> bool:
        """Ki·ªÉm tra files ƒë√£ t·ªìn t·∫°i ch∆∞a"""
        try:
            pdf_path = os.path.join(download_dir, f"{registernummer}_AD.pdf")
            xml_path = os.path.join(download_dir, f"{registernummer}_SI.xml")
            
            # Ki·ªÉm tra PDF v√† XML
            pdf_exists = os.path.exists(pdf_path)
            xml_exists = os.path.exists(xml_path)
            
            if pdf_exists and xml_exists:
                logger.info(f"‚úÖ Files ƒë√£ t·ªìn t·∫°i:")
                logger.info(f"  üìÑ PDF: {pdf_exists}")
                logger.info(f"  üìÑ XML: {xml_exists}")
                return True
            else:
                logger.info(f"‚ùå Files ch∆∞a ƒë·∫ßy ƒë·ªß:")
                logger.info(f"  üìÑ PDF: {pdf_exists}")
                logger.info(f"  üìÑ XML: {xml_exists}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói ki·ªÉm tra files: {str(e)}")
            return False
    
    def _check_files_changed(self, page: Page, download_dir: str, registernummer: str) -> bool:
        """Ki·ªÉm tra files m·ªõi c√≥ kh√°c files c≈© kh√¥ng b·∫±ng c√°ch so s√°nh hash"""
        try:
            # T·∫°o temp directory
            temp_dir = os.path.join(download_dir, '.temp')
            os.makedirs(temp_dir, exist_ok=True)
            
            # Download files m·ªõi v√†o temp
            logger.info("üì• Downloading files m·ªõi ƒë·ªÉ so s√°nh...")
            self._download_documents(page, temp_dir, registernummer)
            
            # So s√°nh hash
            pdf_changed = self._compare_file_hash(
                os.path.join(download_dir, f"{registernummer}_AD.pdf"),
                os.path.join(temp_dir, f"{registernummer}_AD.pdf")
            )
            
            xml_changed = self._compare_file_hash(
                os.path.join(download_dir, f"{registernummer}_SI.xml"),
                os.path.join(temp_dir, f"{registernummer}_SI.xml")
            )
            
            # N·∫øu c√≥ file n√†o thay ƒë·ªïi ‚Üí move temp files sang main dir
            if pdf_changed or xml_changed:
                logger.info(f"üìù Files thay ƒë·ªïi: PDF={pdf_changed}, XML={xml_changed}")
                
                # Move files m·ªõi sang main directory
                if pdf_changed:
                    os.replace(
                        os.path.join(temp_dir, f"{registernummer}_AD.pdf"),
                        os.path.join(download_dir, f"{registernummer}_AD.pdf")
                    )
                if xml_changed:
                    os.replace(
                        os.path.join(temp_dir, f"{registernummer}_SI.xml"),
                        os.path.join(download_dir, f"{registernummer}_SI.xml")
                    )
                
                # Clean up temp
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
                
                return True
            else:
                # Clean up temp
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
                
                return False
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói check files changed: {str(e)}")
            return False
    
    def _compare_file_hash(self, file1: str, file2: str) -> bool:
        """So s√°nh hash c·ªßa 2 files, return True n·∫øu kh√°c nhau"""
        try:
            if not os.path.exists(file1) or not os.path.exists(file2):
                return True  # N·∫øu file kh√¥ng t·ªìn t·∫°i ‚Üí coi nh∆∞ kh√°c
            
            hash1 = self._get_file_hash(file1)
            hash2 = self._get_file_hash(file2)
            
            return hash1 != hash2
            
        except:
            return True
    
    def _get_file_hash(self, filepath: str) -> str:
        """T√≠nh MD5 hash c·ªßa file"""
        try:
            md5_hash = hashlib.md5()
            with open(filepath, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    md5_hash.update(chunk)
            return md5_hash.hexdigest()
        except:
            return ""
    
    def _download_documents(self, page: Page, download_dir: str, registernummer: str):
        """Download AD (PDF) v√† SI (XML)"""
        try:
            # Download AD (PDF)
            logger.info("üì• Downloading AD (PDF)...")
            pdf_path = self._download_ad_pdf(page, download_dir, registernummer)
            
            # Wait for download to complete
            page.wait_for_timeout(3000)
            
            # Reload trang ƒë·ªÉ c√≥ th·ªÉ download SI
            page.reload(wait_until='networkidle')
            page.wait_for_timeout(2000)
            
            # Download SI (XML)
            logger.info("üì• Downloading SI (XML)...")
            self._download_si_xml(page, download_dir, registernummer)
            
            logger.info("‚úÖ ƒê√£ download xong t·∫•t c·∫£ documents")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói download documents: {str(e)}")
    
    def _download_ad_pdf(self, page: Page, download_dir: str, registernummer: str) -> str:
        """Click v√† download AD (PDF)"""
        try:
            # Setup download handler
            with page.expect_download() as download_info:
                # Click v√†o link AD v·ªõi selector ch√≠nh x√°c
                page.click('a[onclick*="Global.Dokumentart.AD"]')
                # Wait for form submission v√† download
                page.wait_for_timeout(5000)
            
            # L∆∞u file
            download = download_info.value
            pdf_path = os.path.join(download_dir, f"{registernummer}_AD.pdf")
            download.save_as(pdf_path)
            
            logger.info(f"‚úÖ ƒê√£ l∆∞u AD PDF: {pdf_path}")
            return pdf_path
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói download AD: {str(e)}")
            return None
    
    def _download_si_xml(self, page: Page, download_dir: str, registernummer: str):
        """Click v√† download SI (XML)"""
        try:
            # Setup download handler
            with page.expect_download() as download_info:
                # Click v√†o link SI v·ªõi selector ch√≠nh x√°c
                page.click('a[onclick*="Global.Dokumentart.SI"]')
                # Wait for form submission v√† download
                page.wait_for_timeout(5000)
            
            # L∆∞u file
            download = download_info.value
            xml_path = os.path.join(download_dir, f"{registernummer}_SI.xml")
            download.save_as(xml_path)
            
            logger.info(f"‚úÖ ƒê√£ l∆∞u SI XML: {xml_path}")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói download SI: {str(e)}")
    
    def _extract_xml_data(self, download_dir: str, registernummer: str) -> Dict:
        """Extract data t·ª´ XML file"""
        try:
            xml_path = os.path.join(download_dir, f"{registernummer}_SI.xml")
            
            if not os.path.exists(xml_path):
                logger.warning(f"‚ö†Ô∏è  XML file kh√¥ng t·ªìn t·∫°i: {xml_path}")
                return {}
            
            logger.info(f"üìä Extracting data t·ª´ XML: {xml_path}")
            xml_data = self.xml_parser.parse_xml_file(xml_path)
            
            # Map XML fields sang CompanyData fields
            # CH·ªà l·∫•y c√°c tr∆∞·ªùng c√≥ trong CompanyData model (27 tr∆∞·ªùng)
            company_data = {}
            
            # Map tr·ª±c ti·∫øp - CH·ªà c√°c tr∆∞·ªùng trong model
            field_mapping = {
                'registernummer': 'registernummer',
                'handelsregister': 'handelsregister', 
                'geschaeftsfuehrer': 'geschaeftsfuehrer',
                'geschaeftsadresse': 'geschaeftsadresse',
                'unternehmenszweck': 'unternehmenszweck',
                'gruendungsdatum': 'gruendungsdatum',
                'land_des_hauptsitzes': 'land_des_hauptsitzes',
                'gerichtsstand': 'gerichtsstand',
                'paragraph_34_gewo': 'paragraph_34_gewo'
                # stammkapital KH√îNG c√≥ trong CompanyData model n√™n kh√¥ng l·∫•y
                # letzte_eintragung, letzte_aenderung, abrufdatum c≈©ng kh√¥ng c√≥ trong model
            }
            
            for xml_field, company_field in field_mapping.items():
                if xml_field in xml_data and xml_data[xml_field] is not None:
                    company_data[company_field] = xml_data[xml_field]
            
            logger.info(f"‚úÖ ƒê√£ extract {len(company_data)} tr∆∞·ªùng t·ª´ XML")
            return company_data
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói extract XML data: {str(e)}")
            return {}
    
    def _extract_pdf_data(self, download_dir: str, registernummer: str) -> Dict:
        """Extract data t·ª´ PDF file"""
        try:
            pdf_path = os.path.join(download_dir, f"{registernummer}_AD.pdf")
            
            if not os.path.exists(pdf_path):
                logger.warning(f"‚ö†Ô∏è  PDF file kh√¥ng t·ªìn t·∫°i: {pdf_path}")
                return {}
            
            logger.info(f"üìä Extracting data t·ª´ PDF: {pdf_path}")
            pdf_data = self.pdf_extractor.extract_from_pdf(pdf_path)
            
            # Map PDF fields sang CompanyData fields
            # CH·ªà l·∫•y c√°c tr∆∞·ªùng c√≥ trong CompanyData model (27 tr∆∞·ªùng)
            company_data = {}
            
            # Map tr·ª±c ti·∫øp (kh√¥ng override n·∫øu XML ƒë√£ c√≥) - CH·ªà c√°c tr∆∞·ªùng trong model
            field_mapping = {
                # PDF c√≥ th·ªÉ backup cho c√°c tr∆∞·ªùng n√†y n·∫øu XML kh√¥ng c√≥:
                'geschaeftsadresse': 'geschaeftsadresse',
                'unternehmenszweck': 'unternehmenszweck',
                'geschaeftsfuehrer': 'geschaeftsfuehrer',
                # 'gruendungsdatum': 'gruendungsdatum',  # KH√îNG l·∫•y t·ª´ PDF v√¨ kh√¥ng ch√≠nh x√°c
                'handelsregister': 'handelsregister',
                'registernummer': 'registernummer'
                # KH√îNG l·∫•y: stammkapital, letzte_eintragung, anzahl_eintragungen, gruendungsdatum
                # V√¨ kh√¥ng c√≥ trong model ho·∫∑c kh√¥ng ch√≠nh x√°c
            }
            
            for pdf_field, company_field in field_mapping.items():
                if pdf_field in pdf_data and pdf_data[pdf_field] is not None:
                    # Ch·ªâ add n·∫øu ch∆∞a c√≥ t·ª´ XML (XML c√≥ priority cao h∆°n)
                    if company_field not in company_data or company_data.get(company_field) is None:
                        company_data[company_field] = pdf_data[pdf_field]
            
            logger.info(f"‚úÖ ƒê√£ extract {len(company_data)} tr∆∞·ªùng t·ª´ PDF")
            return company_data
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói extract PDF data: {str(e)}")
            return {}


def test_from_companies_json(language: str = 'FR'):
    """Test scraper v·ªõi data t·ª´ companies.json"""
    
    companies_file = os.path.join(
        os.path.dirname(os.path.dirname(__file__)), 
        'data', 
        'companies.json'
    )
    
    with open(companies_file, 'r', encoding='utf-8') as f:
        companies = json.load(f)
    
    if companies:
        company = companies[0]
        
        scraper = HandelsregisterScraper(headless=True, language=language)
        
        result = scraper.scrape_company(
            company['company_name'],
            company['registernummer'],
            company['ust_idnr']
        )
        
        print("\n" + "="*60)
        print("üìä K·∫æT QU·∫¢ SCRAPE:")
        print("="*60)
        print(json.dumps(result, indent=2, ensure_ascii=False))
        print("="*60)
    else:
        print("‚ùå Kh√¥ng c√≥ company trong companies.json")


if __name__ == "__main__":
    test_from_companies_json(language='FR')
