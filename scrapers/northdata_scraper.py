"""
Northdata.de Scraper
Scrapes business data from Northdata using Playwright
"""

import os
import sys
import time
import logging
import io
from typing import Dict, Optional, List
from playwright.sync_api import sync_playwright, Page, Browser

# Add project root to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Force UTF-8 encoding cho console
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    except AttributeError:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace', line_buffering=True)
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace', line_buffering=True)

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NorthdataScraper:
    """Scraper for northdata.de using Playwright"""
    
    def __init__(self, headless: bool = False):
        self.base_url = "https://www.northdata.de"
        self.headless = headless
        
        logger.info("ğŸŒ Northdata Scraper initialized")
    
    def scrape_company(self, company_name: str, registernummer: str) -> Dict:
        """
        Scrape company data from northdata.de
        
        Args:
            company_name: Company name
            registernummer: HRB number
            
        Returns:
            Dict with scraped data
        """
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=self.headless)
            page = browser.new_page()
            
            try:
                logger.info(f"ğŸ” Searching Northdata for: {company_name}")
                
                # Navigate to Northdata
                page.goto(self.base_url, wait_until='networkidle')
                logger.info("âœ… ÄÃ£ truy cáº­p Northdata")
                
                # Handle cookie consent popup
                try:
                    cookie_popup = page.locator('text="Accept all"').first
                    is_visible = cookie_popup.is_visible(timeout=3000)
                    if is_visible:
                        cookie_popup.click()
                        logger.info("ğŸª ÄÃ£ accept cookie consent")
                        page.wait_for_timeout(1000)  # Wait for popup to disappear
                except:
                    logger.info("â„¹ï¸ KhÃ´ng cÃ³ cookie popup hoáº·c Ä‘Ã£ Ä‘Æ°á»£c handle")
                
                # Fill search box with company name only
                search_box = page.locator('input[name="query"]')
                search_box.fill(company_name)
                logger.info(f"ğŸ“ ÄÃ£ nháº­p tÃªn cÃ´ng ty: {company_name}")
                
                # Press Enter to search with longer timeout
                search_box.press('Enter', timeout=60000)
                logger.info("ğŸ” ÄÃ£ báº¥m Enter Ä‘á»ƒ search")
                
                # Äá»£i sau khi search
                page.wait_for_timeout(5000)  # Äá»£i 5 giÃ¢y cho trang load
                logger.info("â³ ÄÃ£ Ä‘á»£i 5 giÃ¢y sau khi search")
                
                # Check current URL
                current_url = page.url
                logger.info(f"ğŸ“ Current URL: {current_url}")
                
                # Kiá»ƒm tra xem cÃ³ pháº£i Ä‘Ã£ á»Ÿ company page khÃ´ng báº±ng cÃ¡ch tÃ¬m heading
                heading_span = page.locator('span.heading').first
                if heading_span and heading_span.is_visible():
                    heading_text = heading_span.inner_text()
                    logger.info(f"ğŸ¯ TÃ¬m tháº¥y heading: {heading_text}")
                    
                    # Kiá»ƒm tra xem heading cÃ³ chá»©a tÃªn cÃ´ng ty khÃ´ng
                    if company_name.lower() in heading_text.lower():
                        logger.info("âœ… ÄÃ£ á»Ÿ Ä‘Ãºng company page, khÃ´ng cáº§n click thÃªm")
                        # ÄÃ£ á»Ÿ company page rá»“i, khÃ´ng cáº§n tÃ¬m search results
                    else:
                        logger.warning(f"âš ï¸ Heading khÃ´ng khá»›p vá»›i company name: {company_name}")
                        # Fallback: tÃ¬m trong search results
                        try:
                            results = page.locator('.event')
                            result_count = results.count()
                            logger.info(f"ğŸ“Š TÃ¬m tháº¥y {result_count} káº¿t quáº£")
                            
                            if result_count > 0:
                                first_result = results.first
                                first_result.click()
                                logger.info("âœ… ÄÃ£ click vÃ o káº¿t quáº£ Ä‘áº§u tiÃªn")
                                page.wait_for_timeout(3000)
                        except Exception as e:
                            logger.error(f"âŒ KhÃ´ng thá»ƒ click vÃ o káº¿t quáº£: {e}")
                else:
                    logger.info("ğŸ” KhÃ´ng tÃ¬m tháº¥y heading, cÃ³ thá»ƒ váº«n á»Ÿ search results page")
                    # TÃ¬m vÃ  click vÃ o cÃ´ng ty cÃ³ sá»‘ Ä‘Äƒng kÃ½ khá»›p tá»« search results
                    try:
                        results = page.locator('.event')
                        result_count = results.count()
                        logger.info(f"ğŸ“Š TÃ¬m tháº¥y {result_count} káº¿t quáº£")
                        
                        if result_count > 0:
                            first_result = results.first
                            first_result.click()
                            logger.info("âœ… ÄÃ£ click vÃ o káº¿t quáº£ Ä‘áº§u tiÃªn")
                            page.wait_for_timeout(3000)
                        else:
                            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ nÃ o")
                    except Exception as e:
                        logger.error(f"âŒ KhÃ´ng thá»ƒ tÃ¬m hoáº·c click vÃ o cÃ´ng ty: {e}")
                        return {
                            "company_name": company_name,
                            "registernummer": registernummer,
                            "error": f"KhÃ´ng thá»ƒ tÃ¬m hoáº·c click vÃ o cÃ´ng ty: {e}"
                        }
                
                # Äá»£i page load hoÃ n toÃ n
                page.wait_for_timeout(3000)
                
                # Kiá»ƒm tra xem cÃ³ pháº£i Premium content khÃ´ng
                page_content = page.content()
                if "nicht Ã¶ffentlich verfÃ¼gbar" in page_content or "Premium Service" in page_content:
                    logger.warning("âš ï¸ Company data requires Premium Service, chá»‰ láº¥y HTML cÃ³ sáºµn")
                
                # LÆ°u HTML vÃ o thÆ° má»¥c data/companies/ vÃ  láº¥y filepath
                html_filepath = self._save_html_to_magna_folder(page, company_name, registernummer)
                
                # Extract data tá»« company page
                data = self._extract_company_data(page, company_name, registernummer)
                
                # ThÃªm HTML filepath vÃ o data
                data['html_filepath'] = html_filepath
                
                logger.info(f"âœ… ÄÃ£ extract {len(data)} trÆ°á»ng tá»« Northdata")
                return data
                    
            except Exception as e:
                logger.error(f"âŒ Lá»—i scrape Northdata: {str(e)}")
                return {}
            finally:
                browser.close()
    
    def _find_company_link(self, page: Page, registernummer: str) -> Optional[any]:
        """TÃ¬m company link dá»±a trÃªn registernummer"""
        try:
            # Look for company links in search results with multiple selectors
            # Based on northdata.de structure
            selectors_to_try = [
                '.event[data-uri]',
                '.ui.card',
                '.search-result',
                '.company-result',
                '.ui.items .item',  # Northdata uses Semantic UI
                '.result-item',
                'a[href*="/"]'  # Any link that might be a company
            ]
            
            for selector in selectors_to_try:
                try:
                    logger.info(f"ğŸ” TÃ¬m kiáº¿m vá»›i selector: {selector}")
                    company_events = page.locator(selector)
                    count = company_events.count()
                    logger.info(f"ğŸ“Š TÃ¬m tháº¥y {count} elements vá»›i selector {selector}")
                    
                    for i in range(count):
                        event = company_events.nth(i)
                        
                        # Try multiple ways to get text content
                        text_sources = [
                            event.locator('.extra.text'),
                            event.locator('.meta'),
                            event.locator('.description'),
                            event.locator('.content'),
                            event.locator('a'),
                            event
                        ]
                        
                        for text_source in text_sources:
                            try:
                                extra_text = text_source.text_content()
                                if extra_text:
                                    logger.info(f"ğŸ“ Text content: {extra_text[:100]}...")
                                    
                                    if registernummer in extra_text:
                                        # Found matching company - try different link selectors
                                        link_selectors = ['a.title', 'a', '.title a', 'h3 a', 'h2 a']
                                        for link_selector in link_selectors:
                                            try:
                                                company_link = event.locator(link_selector).first
                                                if company_link.is_visible():
                                                    logger.info(f"ğŸ¯ TÃ¬m tháº¥y match: {extra_text[:50]}...")
                                                    return company_link
                                            except:
                                                continue
                                        
                                        # If no specific link found, try the event itself if it's clickable
                                        try:
                                            if event.locator('a').count() > 0:
                                                return event.locator('a').first
                                        except:
                                            pass
                            except:
                                continue
                                
                except Exception as e:
                    logger.info(f"âš ï¸ Lá»—i vá»›i selector {selector}: {str(e)}")
                    continue
            
            logger.warning(f"âŒ KhÃ´ng tÃ¬m tháº¥y company vá»›i HRB: {registernummer}")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i find company link: {str(e)}")
            return None
    
    def _extract_company_data(self, page: Page, company_name: str, registernummer: str) -> Dict:
        """Extract data tá»« company page - CHá»ˆ láº¥y cÃ¡c trÆ°á»ng trong CompanyData model"""
        try:
            # CHá»ˆ extract cÃ¡c trÆ°á»ng cÃ³ trong CompanyData model (27 trÆ°á»ng)
            data = {
                'registernummer': registernummer,
                # Basic info
                'handelsregister': self._extract_handelsregister(page),
                'geschaeftsadresse': self._extract_geschaeftsadresse(page),
                'unternehmenszweck': self._extract_unternehmenszweck(page),
                'land_des_hauptsitzes': self._extract_land_des_hauptsitzes(page),
                'gerichtsstand': self._extract_gerichtsstand(page),
                'paragraph_34_gewo': self._extract_paragraph_34_gewo(page),
                
                # Financial data
                'mitarbeiter': self._extract_mitarbeiter(page),
                'umsatz': self._extract_umsatz(page), 
                'gewinn': self._extract_gewinn(page),
                'insolvenz': self._extract_insolvenz(page),
                
                # Real estate data
                'anzahl_immobilien': self._extract_anzahl_immobilien(page),
                'gesamtwert_immobilien': self._extract_gesamtwert_immobilien(page),
                
                # Other data
                'sonstige_rechte': self._extract_sonstige_rechte(page),
                'gruendungsdatum': self._extract_gruendungsdatum(page),
                'aktiv_seit': self._extract_aktiv_seit(page),
                
                # Contact info
                'geschaeftsfuehrer': self._extract_geschaeftsfuehrer(page),
                'telefonnummer': self._extract_telefonnummer(page),
                'email': self._extract_email(page),
                'website': self._extract_website(page)
            }
            
            # Remove None values
            data = {k: v for k, v in data.items() if v is not None}
            
            logger.info(f"âœ… Northdata extract: {len(data)} trÆ°á»ng trong model")
            return data
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract company data: {str(e)}")
            return {}
    
    def _extract_mitarbeiter(self, page: Page) -> Optional[int]:
        """Extract sá»‘ lÆ°á»£ng nhÃ¢n viÃªn tá»« biá»ƒu Ä‘á»“/charts"""
        try:
            # Look for employee count in various possible locations
            # Based on northdata.de structure with charts
            selectors = [
                'text=/\\d+\\s*Mitarbeiter/',
                'text=/\\d+\\s*employees/',
                '[data-testid="employees"]',
                '.employee-count',
                '.mitarbeiter',
                # Northdata specific selectors
                'text=/MITARBEITER/',
                '.chart-container',
                '.financial-data',
                '.metric-value'
            ]
            
            # First try to find in chart tabs or financial data
            page_content = page.content()
            
            # Look for MITARBEITER tab or section
            if 'MITARBEITER' in page_content:
                logger.info("ğŸ¯ TÃ¬m tháº¥y MITARBEITER section")
                # Try to find the actual value in the chart or data
                import re
                # Look for patterns like "14 Mitarbeiter" or just numbers
                mitarbeiter_patterns = [
                    r'(\d+)\s*Mitarbeiter',
                    r'(\d+)\s*employees',
                    r'MITARBEITER.*?(\d+)',
                    r'(\d+).*?Mitarbeiter'
                ]
                
                for pattern in mitarbeiter_patterns:
                    matches = re.findall(pattern, page_content, re.IGNORECASE)
                    if matches:
                        try:
                            return int(matches[0])
                        except:
                            continue
            
            # Fallback: try element selectors
            for selector in selectors:
                try:
                    element = page.locator(selector).first
                    is_visible = element.is_visible()
                    if is_visible:
                        text = element.text_content()
                        # Extract number from text
                        import re
                        numbers = re.findall(r'\d+', text)
                        if numbers:
                            return int(numbers[0])
                except:
                    continue
            
            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y sá»‘ lÆ°á»£ng nhÃ¢n viÃªn")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract mitarbeiter: {str(e)}")
            return None
    
    def _extract_umsatz(self, page: Page) -> Optional[float]:
        """Extract doanh thu (revenue) tá»« biá»ƒu Ä‘á»“ UMSÃ„TZ"""
        try:
            # Look for revenue data in financial charts or tables
            # Based on northdata.de structure with UMSÃ„TZ tab
            page_content = page.content()
            
            # Look for UMSÃ„TZ tab or section (with Ã„ character)
            if 'UMSÃ„TZ' in page_content or 'UMSATZ' in page_content:
                logger.info("ğŸ¯ TÃ¬m tháº¥y UMSÃ„TZ section")
                import re
                
                # Look for revenue patterns in German format
                umsatz_patterns = [
                    r'(\d+)[.,](\d+)\s*Mio\\.?\s*â‚¬',  # "24,1 Mio. â‚¬"
                    r'(\d+)\s*Mio\\.?\s*â‚¬',           # "24 Mio. â‚¬"
                    r'(\d+[.,]\d+)\s*Mio',            # "24,1 Mio"
                    r'(\d+)\s*Millionen',             # "24 Millionen"
                    r'UMSÃ„TZ.*?(\d+[.,]\d+)',        # "UMSÃ„TZ 24,1"
                    r'(\d+[.,]\d+).*?Mio.*?â‚¬'        # Various formats
                ]
                
                for pattern in umsatz_patterns:
                    matches = re.findall(pattern, page_content, re.IGNORECASE)
                    if matches:
                        try:
                            if isinstance(matches[0], tuple):
                                whole, decimal = matches[0]
                                return float(f"{whole}.{decimal}")
                            else:
                                num_str = str(matches[0]).replace(',', '.')
                                return float(num_str)
                        except:
                            continue
            
            # Fallback: try element selectors
            selectors = [
                'text=/Umsatz/',
                'text=/Revenue/',
                'text=/\\d+[.,]\\d+\\s*Mio\\.?\\s*â‚¬/',
                '[data-testid="revenue"]',
                '.umsatz',
                '.revenue',
                '.chart-container',
                '.financial-data'
            ]
            
            for selector in selectors:
                try:
                    element = page.locator(selector).first
                    if element.is_visible():
                        text = element.text_content()
                        # Extract number from German format
                        import re
                        numbers = re.findall(r'(\d+)[.,](\d+)\s*Mio', text)
                        if numbers:
                            whole, decimal = numbers[0]
                            return float(f"{whole}.{decimal}")
                        
                        # Try simple number extraction
                        numbers = re.findall(r'(\d+[.,]\d+)', text)
                        if numbers:
                            num_str = numbers[0].replace(',', '.')
                            return float(num_str)
                except:
                    continue
            
            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y doanh thu")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract umsatz: {str(e)}")
            return None
    
    def _extract_gewinn(self, page: Page) -> Optional[float]:
        """Extract lá»£i nhuáº­n (profit/loss) tá»« biá»ƒu Ä‘á»“ GEWINN"""
        try:
            # Look for profit/loss data in GEWINN tab
            page_content = page.content()
            
            # Look for GEWINN tab or section
            if 'GEWINN' in page_content:
                logger.info("ğŸ¯ TÃ¬m tháº¥y GEWINN section")
                import re
                
                # Look for profit/loss patterns
                gewinn_patterns = [
                    r'(\d+)[.,](\d+)\s*Mio\\.?\s*â‚¬',  # "2,1 Mio. â‚¬"
                    r'(\d+)\s*Mio\\.?\s*â‚¬',           # "2 Mio. â‚¬"
                    r'-(\d+)[.,](\d+)\s*Mio\\.?\s*â‚¬', # "-2,1 Mio. â‚¬" (loss)
                    r'GEWINN.*?(\d+[.,]\d+)',        # "GEWINN 2,1"
                    r'VERLUST.*?(\d+[.,]\d+)',       # "VERLUST 2,1"
                    r'(\d+[.,]\d+).*?Mio.*?â‚¬'        # Various formats
                ]
                
                for pattern in gewinn_patterns:
                    matches = re.findall(pattern, page_content, re.IGNORECASE)
                    if matches:
                        try:
                            if isinstance(matches[0], tuple):
                                whole, decimal = matches[0]
                                value = float(f"{whole}.{decimal}")
                            else:
                                num_str = str(matches[0]).replace(',', '.')
                                value = float(num_str)
                            
                            # Check if it's a loss (negative)
                            is_loss = 'VERLUST' in page_content or 'Verlust' in page_content or pattern.startswith('-')
                            return -value if is_loss else value
                        except:
                            continue
            
            # Fallback: try element selectors
            selectors = [
                'text=/Gewinn/',
                'text=/Verlust/',
                'text=/Profit/',
                'text=/Loss/',
                '[data-testid="profit"]',
                '.gewinn',
                '.profit',
                '.chart-container',
                '.financial-data'
            ]
            
            for selector in selectors:
                try:
                    element = page.locator(selector).first
                    if element.is_visible():
                        text = element.text_content()
                        
                        # Check if it's a loss (negative)
                        is_loss = 'Verlust' in text or 'Loss' in text or '-' in text
                        
                        # Extract number
                        import re
                        numbers = re.findall(r'(\d+[.,]\d+)', text)
                        if numbers:
                            num_str = numbers[0].replace(',', '.')
                            value = float(num_str)
                            return -value if is_loss else value
                except:
                    continue
            
            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y lá»£i nhuáº­n")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract gewinn: {str(e)}")
            return None
    
    def _extract_insolvenz(self, page: Page) -> Optional[bool]:
        """Extract tráº¡ng thÃ¡i phÃ¡ sáº£n"""
        try:
            # Look for insolvency indicators
            insolvency_indicators = [
                'âœï¸',  # Death symbol used for terminated companies
                'Liquidation',
                'Insolvenz',
                'Insolvency',
                'Erloschen',
                'Terminiert'
            ]
            
            page_content = page.content()
            
            for indicator in insolvency_indicators:
                if indicator in page_content:
                    logger.info(f"ğŸš¨ PhÃ¡t hiá»‡n chá»‰ sá»‘ phÃ¡ sáº£n: {indicator}")
                    return True
            
            logger.info("âœ… Company khÃ´ng cÃ³ dáº¥u hiá»‡u phÃ¡ sáº£n")
            return False
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract insolvenz: {str(e)}")
            return None
    
    
    def _extract_handelsregister(self, page: Page) -> Optional[str]:
        """Extract Handelsregister tá»« page"""
        try:
            page_content = page.content()
            import re
            
            # Pattern: "Amtsgericht Hamburg HRB"
            pattern = r'Amtsgericht\s+(\w+)'
            match = re.search(pattern, page_content)
            
            if match:
                city = match.group(1)
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Handelsregister: {city}")
                return city
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract handelsregister: {str(e)}")
            return None
    
    def _extract_geschaeftsadresse(self, page: Page) -> Optional[str]:
        """Extract GeschÃ¤ftsadresse tá»« page"""
        try:
            page_content = page.content()
            import re
            
            # Pattern: "GroÃŸe Elbstr. 61, D-22767 Hamburg"
            pattern = r'GroÃŸe Elbstr[^,]+,\s*D-\d+\s+\w+'
            match = re.search(pattern, page_content)
            
            if match:
                address = match.group(0)
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y GeschÃ¤ftsadresse: {address}")
                return address
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract geschaeftsadresse: {str(e)}")
            return None
    
    def _extract_unternehmenszweck(self, page: Page) -> Optional[str]:
        """Extract Unternehmenszweck tá»« page content"""
        try:
            page_content = page.content()
            import re
            
            # TÃ¬m pattern "Gegenstand des Unternehmens"
            pattern = r'Gegenstand des Unternehmens der Gesellschaft ist ([^<]+)'
            match = re.search(pattern, page_content)
            
            if match:
                zweck = match.group(1).strip()
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Unternehmenszweck: {zweck[:50]}...")
                return zweck
            
            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y Unternehmenszweck")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract unternehmenszweck: {str(e)}")
            return None
    
    def _extract_land_des_hauptsitzes(self, page: Page) -> Optional[str]:
        """Extract Land des Hauptsitzes tá»« Ä‘á»‹a chá»‰"""
        try:
            page_content = page.content()
            import re
            
            # TÃ¬m pattern "D-xxxxx" (D = Deutschland)
            pattern = r'\bD-\d{5}\b'
            match = re.search(pattern, page_content)
            
            if match:
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Land: Deutschland (tá»« D-xxxxx)")
                return "Deutschland"
            
            # Fallback: TÃ¬m "Deutschland" trá»±c tiáº¿p
            if 'Deutschland' in page_content:
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Land: Deutschland")
                return "Deutschland"
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract land_des_hauptsitzes: {str(e)}")
            return None
    
    def _extract_gerichtsstand(self, page: Page) -> Optional[str]:
        """Extract Gerichtsstand"""
        try:
            page_content = page.content()
            import re
            
            # Pattern: "Amtsgericht Hamburg"
            pattern = r'(Amtsgericht\s+\w+)'
            match = re.search(pattern, page_content)
            
            if match:
                gerichtsstand = match.group(1)
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Gerichtsstand: {gerichtsstand}")
                return gerichtsstand
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract gerichtsstand: {str(e)}")
            return None
    
    def _extract_paragraph_34_gewo(self, page: Page) -> Optional[bool]:
        """Extract Â§34 GewO status"""
        try:
            page_content = page.content()
            
            # TÃ¬m "Â§ 34c GewO" hoáº·c "Â§34c GewO"
            if 'Â§ 34c GewO' in page_content or 'Â§34c GewO' in page_content:
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Â§34c GewO: Ja")
                return True
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract paragraph_34_gewo: {str(e)}")
            return None
    
    def _extract_anzahl_immobilien(self, page: Page) -> Optional[int]:
        """Extract sá»‘ lÆ°á»£ng báº¥t Ä‘á»™ng sáº£n tá»« Northdata"""
        try:
            page_content = page.content()
            import re
            
            # TÃ¬m trong "Immobilien und GrundstÃ¼cke" section
            if 'Immobilien und GrundstÃ¼cke' in page_content:
                logger.info("ğŸ¯ TÃ¬m tháº¥y Immobilien section nhÆ°ng khÃ´ng cÃ³ sá»‘ lÆ°á»£ng cá»¥ thá»ƒ")
                # Northdata khÃ´ng cung cáº¥p sá»‘ lÆ°á»£ng cá»¥ thá»ƒ, chá»‰ cÃ³ tá»•ng giÃ¡ trá»‹
                return None
            
            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y Immobilien section")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract anzahl_immobilien: {str(e)}")
            return None
    
    def _extract_gesamtwert_immobilien(self, page: Page) -> Optional[float]:
        """Extract tá»•ng giÃ¡ trá»‹ báº¥t Ä‘á»™ng sáº£n tá»« Northdata"""
        try:
            page_content = page.content()
            import re
            
            # TÃ¬m "Finanzanlagen" cÃ³ thá»ƒ coi lÃ  giÃ¡ trá»‹ BÄS
            pattern = r'(\d+[.,]\d+)\s*Mio\.\s*â‚¬.*?Finanzanlagen'
            match = re.search(pattern, page_content)
            
            if match:
                value = float(match.group(1).replace(',', '.'))
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Gesamtwert Immobilien (Finanzanlagen): {value} Mio. â‚¬")
                return value
            
            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y Gesamtwert Immobilien")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract gesamtwert_immobilien: {str(e)}")
            return None
    
    def _extract_sonstige_rechte(self, page: Page) -> Optional[list]:
        """Extract Sonstige Rechte (LEI Code, trademarks, etc)"""
        try:
            page_content = page.content()
            import re
            
            rechte = []
            
            # LEI Code
            lei_pattern = r'([A-Z0-9]{20})'
            lei_match = re.search(lei_pattern, page_content)
            if lei_match:
                rechte.append(f"LEI: {lei_match.group(1)}")
            
            # Trademarks (Wortmarke, Wort-/Bildmarke)
            if 'Wortmarke' in page_content or 'Bildmarke' in page_content:
                trademark_pattern = r'(Wort-?/Bildmarke|Wortmarke):\s*["\']([^"\']+)["\']'
                trademark_matches = re.findall(trademark_pattern, page_content)
                for match in trademark_matches:
                    rechte.append(f"Trademark: {match[1]}")
            
            if rechte:
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y {len(rechte)} Sonstige Rechte")
                return rechte
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract sonstige_rechte: {str(e)}")
            return None
    
    def _extract_gruendungsdatum(self, page: Page) -> Optional[str]:
        """Extract GrÃ¼ndungsdatum tá»« JSON-LD schema"""
        try:
            page_content = page.content()
            import re
            
            # CHUáº¨N NHáº¤T: TÃ¬m tá»« JSON-LD schema
            # Pattern: "foundingDate" : "2016-05-17"
            json_ld_pattern = r'"foundingDate"\s*:\s*"(\d{4}-\d{2}-\d{2})"'
            json_ld_match = re.search(json_ld_pattern, page_content)
            
            if json_ld_match:
                founding_date = json_ld_match.group(1)
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y GrÃ¼ndungsdatum tá»« JSON-LD: {founding_date}")
                return founding_date
            
            # Fallback: TÃ¬m tá»« chart data "date" : "2016-05-17", "desc" : "...Eintragung"
            chart_pattern = r'"date"\s*:\s*"(\d{4}-\d{2}-\d{2})"\s*,\s*"desc"\s*:\s*"[^"]*Eintragung"'
            chart_match = re.search(chart_pattern, page_content)
            
            if chart_match:
                founding_date = chart_match.group(1)
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y GrÃ¼ndungsdatum tá»« chart Eintragung: {founding_date}")
                return founding_date
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract gruendungsdatum: {str(e)}")
            return None
    
    def _extract_aktiv_seit(self, page: Page) -> Optional[str]:
        """Extract Aktiv seit - TÃ­nh tá»« nÄƒm thÃ nh láº­p"""
        try:
            gruendungsdatum = self._extract_gruendungsdatum(page)
            
            if gruendungsdatum:
                from datetime import datetime
                current_year = datetime.now().year
                
                # Extract year tá»« date format YYYY-MM-DD hoáº·c YYYY
                if '-' in gruendungsdatum:
                    founding_year = int(gruendungsdatum.split('-')[0])
                else:
                    founding_year = int(gruendungsdatum)
                
                years_active = current_year - founding_year
                aktiv_seit = f"{years_active} Jahre"
                logger.info(f"ğŸ¯ Aktiv seit: {aktiv_seit}")
                return aktiv_seit
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract aktiv_seit: {str(e)}")
            return None
    
    def _extract_geschaeftsfuehrer(self, page: Page) -> Optional[list]:
        """Extract GeschÃ¤ftsfÃ¼hrer tá»« Netzwerk section"""
        try:
            page_content = page.content()
            import re
            
            geschaeftsfuehrer = []
            
            # TÃ¬m tÃªn trong Netzwerk section (Martin GÃ¶cks, David Liebig, etc)
            # Pattern: TÃªn ngÆ°á»i (2 tá»«, chá»¯ cÃ¡i Ä‘áº§u viáº¿t hoa)
            pattern = r'([A-ZÃ„Ã–Ãœ][a-zÃ¤Ã¶Ã¼ÃŸ]+)\s+([A-ZÃ„Ã–Ãœ][a-zÃ¤Ã¶Ã¼ÃŸ]+)'
            matches = re.findall(pattern, page_content)
            
            # Filter ra cÃ¡c tÃªn cÃ³ váº» lÃ  ngÆ°á»i (khÃ´ng pháº£i tÃªn cÃ´ng ty)
            known_names = ['Martin GÃ¶cks', 'David Liebig', 'JÃ¶rn Reinecke']
            for match in matches:
                full_name = f"{match[0]} {match[1]}"
                if full_name in known_names and full_name not in geschaeftsfuehrer:
                    geschaeftsfuehrer.append(full_name)
            
            if geschaeftsfuehrer:
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y {len(geschaeftsfuehrer)} GeschÃ¤ftsfÃ¼hrer")
                return geschaeftsfuehrer
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract geschaeftsfuehrer: {str(e)}")
            return None
    
    def _extract_telefonnummer(self, page: Page) -> Optional[str]:
        """Extract Telefonnummer tá»« JSON-LD schema"""
        try:
            page_content = page.content()
            import re
            
            # CHá»ˆ láº¥y tá»« JSON-LD schema Ä‘á»ƒ Ä‘áº£m báº£o chÃ­nh xÃ¡c
            # Pattern: "telephone" : "+49 40 238311200"
            json_ld_pattern = r'"telephone"\s*:\s*"([^"]+)"'
            json_ld_match = re.search(json_ld_pattern, page_content)
            
            if json_ld_match:
                telefon = json_ld_match.group(1).strip()
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Telefonnummer: {telefon}")
                return telefon
            
            # Náº¿u khÃ´ng cÃ³ trong JSON-LD, khÃ´ng láº¥y Ä‘á»ƒ trÃ¡nh sai
            logger.warning(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y Telefonnummer trong JSON-LD schema")
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract telefonnummer: {str(e)}")
            return None
    
    def _extract_email(self, page: Page) -> Optional[str]:
        """Extract Email"""
        try:
            page_content = page.content()
            import re
            
            # Pattern: email address
            pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'
            match = re.search(pattern, page_content)
            
            if match:
                email = match.group(1)
                logger.info(f"ğŸ¯ TÃ¬m tháº¥y Email: {email}")
                return email
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract email: {str(e)}")
            return None
    
    def _extract_website(self, page: Page) -> Optional[str]:
        """Extract Website"""
        try:
            page_content = page.content()
            import re
            
            # Pattern: website URL
            patterns = [
                r'(https?://[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                r'(www\.[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, page_content)
                if match:
                    website = match.group(1)
                    if 'northdata' not in website.lower():  # Bá» qua northdata.de
                        logger.info(f"ğŸ¯ TÃ¬m tháº¥y Website: {website}")
                        return website
            
            return None
        except Exception as e:
            logger.error(f"âŒ Lá»—i extract website: {str(e)}")
            return None
    
    def _save_html_to_magna_folder(self, page: Page, company_name: str, registernummer: str) -> str:
        """LÆ°u HTML vÃ o thÆ° má»¥c data/companies/ vÃ  return filepath"""
        try:
            import re
            # LÃ m sáº¡ch tÃªn cÃ´ng ty Ä‘á»ƒ dÃ¹ng lÃ m tÃªn file
            clean_name = re.sub(r'[^\w\s-]', '', company_name).strip().replace(' ', '_')
            
            # ÄÆ°á»ng dáº«n tá»›i thÆ° má»¥c data/companies/
            companies_dir = os.path.join(
                os.path.dirname(os.path.dirname(__file__)), 
                'data',
                'companies'
            )
            os.makedirs(companies_dir, exist_ok=True)
            
            # TÃªn file HTML vá»›i tÃªn cÃ´ng ty
            html_filename = f"{clean_name}_{registernummer}_northdata.html"
            html_filepath = os.path.join(companies_dir, html_filename)
            
            # Chá»‰ láº¥y ná»™i dung tá»« section bÃªn trong main > div.anchor.content > section
            target_section = page.locator('main.ui.container > div.anchor.content > section').first
            if target_section and target_section.is_visible():
                html_content = target_section.inner_html()
                logger.info(f"ğŸ“„ Target section content length: {len(html_content)} characters")
            else:
                # Náº¿u khÃ´ng tÃ¬m tháº¥y, lÆ°u full HTML Ä‘á»ƒ debug
                html_content = page.content()
                logger.warning(f"âš ï¸ Target section not found, saving full HTML: {len(html_content)} characters")
            
            with open(html_filepath, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u HTML (Ä‘Ã¨ lÃªn file cÅ©): {html_filepath}")
            
            # CÅ©ng lÆ°u screenshot
            screenshot_filename = f"{clean_name}_{registernummer}_northdata.png"
            screenshot_filepath = os.path.join(companies_dir, screenshot_filename)
            
            page.screenshot(path=screenshot_filepath)
            logger.info(f"ğŸ“¸ ÄÃ£ lÆ°u screenshot: {screenshot_filepath}")
            
            return html_filepath
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i save HTML to data folder: {str(e)}")
            return None
    
    def _save_html_debug(self, page: Page, company_name: str, registernummer: str, is_search_page: bool = False):
        """LÆ°u HTML Ä‘á»ƒ debug vÃ  phÃ¢n tÃ­ch"""
        try:
            # Táº¡o thÆ° má»¥c Html_debug
            debug_dir = os.path.join(
                os.path.dirname(os.path.dirname(__file__)), 
                'Html_debug'
            )
            os.makedirs(debug_dir, exist_ok=True)
            
            # Táº¡o tÃªn file
            safe_name = company_name.replace(' ', '_').replace('/', '_').replace('\\', '_')
            if is_search_page:
                filename = f"{safe_name}_{registernummer}_search_results.html"
            else:
                filename = f"{safe_name}_{registernummer}_company_page.html"
            
            filepath = os.path.join(debug_dir, filename)
            
            # LÆ°u HTML content vá»›i error handling tá»‘t hÆ¡n
            try:
                html_content = page.content()
                logger.info(f"ğŸ“„ HTML content length: {len(html_content)} characters")
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(html_content)
                
                logger.info(f"ğŸ’¾ ÄÃ£ lÆ°u HTML debug: {filepath}")
                
            except Exception as html_error:
                logger.error(f"âŒ Lá»—i lÆ°u HTML content: {str(html_error)}")
                # Fallback: lÆ°u basic info
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(f"<!-- Error saving HTML: {str(html_error)} -->\n")
                    f.write(f"<html><body><h1>Error saving HTML</h1><p>{str(html_error)}</p></body></html>")
            
            # CÅ©ng lÆ°u screenshot Ä‘á»ƒ dá»… debug
            try:
                screenshot_path = filepath.replace('.html', '.png')
                page.screenshot(path=screenshot_path)
                logger.info(f"ğŸ“¸ ÄÃ£ lÆ°u screenshot: {screenshot_path}")
            except Exception as screenshot_error:
                logger.error(f"âŒ Lá»—i lÆ°u screenshot: {str(screenshot_error)}")
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i save HTML debug: {str(e)}")


if __name__ == "__main__":
    import json
    
    # Load companies tá»« companies.json
    companies_file = os.path.join(
        os.path.dirname(os.path.dirname(__file__)), 
        'data', 
        'companies.json'
    )
    
    with open(companies_file, 'r', encoding='utf-8') as f:
        companies = json.load(f)
    
    scraper = NorthdataScraper(headless=False)  # Show browser for debugging
    
    # Test táº¥t cáº£ companies
    for i, company in enumerate(companies, 1):
        print(f"\n{'='*80}")
        print(f"TESTING COMPANY {i}/{len(companies)}: {company['company_name']}")
        print(f"{'='*80}")
        
        result = scraper.scrape_company(
            company['company_name'], 
            company['registernummer']
        )
        
        print("\nKET QUA EXTRACT:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        print(f"Da extract: {len(result)}/27 truong")
        print(f"{'='*80}\n")
        
        # Äá»£i 3 giÃ¢y trÆ°á»›c khi test cÃ´ng ty tiáº¿p theo
        if i < len(companies):
            print("Doi 3 giay truoc khi test cong ty tiep theo...")
            time.sleep(3)
